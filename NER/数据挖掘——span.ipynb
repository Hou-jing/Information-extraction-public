{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Global_pointer_torch版本.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E84fnjSBNDS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "文件目录为：\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "HT6BUOwDP88f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "文件用于预测cullener，其中测试集的数据来自于验证集的后500条"
      ],
      "metadata": {
        "id": "3YI4oKg3P_GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install git-lfs\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/bert-base-chinese\n",
        "!cd bert-base-chinese/\n",
        "!git lfs install\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j69mAlpwNDaM",
        "outputId": "c17c47ef-b0dc-4b9d-d60c-9408ccac3741"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Git LFS initialized.\n",
            "Cloning into 'bert-base-chinese'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 42 (delta 15), reused 0 (delta 0), pack-reused 0\n",
            "Unpacking objects: 100% (42/42), done.\n",
            "Filtering content: 100% (3/3), 1.20 GiB | 114.99 MiB/s, done.\n",
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q pro2.zip"
      ],
      "metadata": {
        "id": "9sPc75XvM8Da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346404a3-cee6-40b9-e2fd-765dea44b04f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open pro2.zip, pro2.zip.zip or pro2.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utils"
      ],
      "metadata": {
        "id": "_0EkBjhHL5Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Date: 2021-06-01 22:29:43\n",
        "LastEditors: GodK\n",
        "LastEditTime: 2021-07-31 19:30:18\n",
        "\"\"\"\n",
        "import torch\n",
        "\n",
        "\n",
        "def multilabel_categorical_crossentropy(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    https://kexue.fm/archives/7359\n",
        "    \"\"\"\n",
        "    y_pred = (1 - 2 * y_true) * y_pred  # -1 -> pos classes, 1 -> neg classes\n",
        "    y_pred_neg = y_pred - y_true * 1e12  # mask the pred outputs of pos classes\n",
        "    y_pred_pos = (y_pred - (1 - y_true) * 1e12)  # mask the pred outputs of neg classes\n",
        "    zeros = torch.zeros_like(y_pred[..., :1])\n",
        "    y_pred_neg = torch.cat([y_pred_neg, zeros], dim=-1)\n",
        "    y_pred_pos = torch.cat([y_pred_pos, zeros], dim=-1)\n",
        "    neg_loss = torch.logsumexp(y_pred_neg, dim=-1)\n",
        "    pos_loss = torch.logsumexp(y_pred_pos, dim=-1)\n",
        "\n",
        "    return (neg_loss + pos_loss).mean()\n",
        "\n",
        "\n",
        "class Preprocessor(object):\n",
        "    def __init__(self, tokenizer, add_special_tokens=True):\n",
        "        super(Preprocessor, self).__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.add_special_tokens = add_special_tokens\n",
        "\n",
        "    def get_ent2token_spans(self, text, entity_list):\n",
        "        \"\"\"实体列表转为token_spans\n",
        "\n",
        "        Args:\n",
        "            text (str): 原始文本\n",
        "            entity_list (list): [(start, end, ent_type),(start, end, ent_type)...]\n",
        "        \"\"\"\n",
        "        ent2token_spans = []\n",
        "\n",
        "        inputs = self.tokenizer(text, add_special_tokens=self.add_special_tokens, return_offsets_mapping=True)\n",
        "        token2char_span_mapping = inputs[\"offset_mapping\"]\n",
        "        text2tokens = self.tokenizer.tokenize(text, add_special_tokens=self.add_special_tokens)\n",
        "\n",
        "        for ent_span in entity_list:\n",
        "            ent = text[ent_span[0]:ent_span[1] + 1]\n",
        "            ent2token = self.tokenizer.tokenize(ent, add_special_tokens=False)\n",
        "\n",
        "            # 寻找ent的token_span\n",
        "            token_start_indexs = [i for i, v in enumerate(text2tokens) if v == ent2token[0]]\n",
        "\n",
        "            token_end_indexs = [i for i, v in enumerate(text2tokens) if v == ent2token[-1]]\n",
        "\n",
        "            token_start_index = list(filter(lambda x: token2char_span_mapping[x][0] == ent_span[0], token_start_indexs))\n",
        "            token_end_index = list(filter(lambda x: token2char_span_mapping[x][-1] - 1 == ent_span[1], token_end_indexs))  # token2char_span_mapping[x][-1]-1 减1是因为原始的char_span是闭区间，而token2char_span是开区间\n",
        "\n",
        "            if len(token_start_index) == 0 or len(token_end_index) == 0:\n",
        "                # print(f'[{ent}] 无法对应到 [{text}] 的token_span，已丢弃')\n",
        "                continue\n",
        "            token_span = (token_start_index[0], token_end_index[0], ent_span[2])\n",
        "\n",
        "            ent2token_spans.append(token_span)\n",
        "        return ent2token_spans\n"
      ],
      "metadata": {
        "id": "GCLTVFtVL4V3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global_pointer.py"
      ],
      "metadata": {
        "id": "GDakaPz9Lysq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QrfedNMrLhem"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Date: 2021-06-02 00:33:09\n",
        "LastEditors: GodK\n",
        "\"\"\"\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.length = len(data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "class DataMaker(object):\n",
        "    def __init__(self, tokenizer, add_special_tokens = True):\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.add_special_tokens = add_special_tokens\n",
        "        self.preprocessor = Preprocessor(tokenizer, self.add_special_tokens)\n",
        "\n",
        "    def generate_inputs(self, datas, max_seq_len, ent2id, data_type=\"train\"):\n",
        "        \"\"\"生成喂入模型的数据\n",
        "\n",
        "        Args:\n",
        "            datas (list): json格式的数据[{'text':'','entity_list':[(start,end,ent_type),()]}]\n",
        "            max_seq_len (int): 句子最大token数量\n",
        "            ent2id (dict): ent到id的映射\n",
        "            data_type (str, optional): data类型. Defaults to \"train\".\n",
        "\n",
        "        Returns:\n",
        "            list: [(sample, input_ids, attention_mask, token_type_ids, labels),(),()...]\n",
        "        \"\"\"\n",
        "\n",
        "        ent_type_size = len(ent2id)  # 实体类别\n",
        "\n",
        "        all_inputs = []\n",
        "        for sample in datas:\n",
        "            inputs = self.tokenizer(\n",
        "                sample[\"text\"],\n",
        "                max_length=max_seq_len,\n",
        "                truncation=True,\n",
        "                padding='max_length'\n",
        "            )\n",
        "\n",
        "            labels = None\n",
        "            if data_type != \"test\":\n",
        "                ent2token_spans = self.preprocessor.get_ent2token_spans(\n",
        "                    sample[\"text\"], sample[\"entity_list\"]\n",
        "                )\n",
        "                labels = np.zeros((ent_type_size, max_seq_len, max_seq_len))\n",
        "                for start, end, label in ent2token_spans:\n",
        "                    labels[ent2id[label], start, end] = 1\n",
        "            inputs[\"labels\"] = labels\n",
        "\n",
        "            input_ids = torch.tensor(inputs[\"input_ids\"]).long()\n",
        "            attention_mask = torch.tensor(inputs[\"attention_mask\"]).long()\n",
        "            token_type_ids = torch.tensor(inputs[\"token_type_ids\"]).long()\n",
        "            if labels is not None:\n",
        "                labels = torch.tensor(inputs[\"labels\"]).long()\n",
        "\n",
        "            sample_input = (sample, input_ids, attention_mask, token_type_ids, labels)\n",
        "\n",
        "            all_inputs.append(sample_input)\n",
        "        return all_inputs\n",
        "    \n",
        "    def generate_batch(self, batch_data, max_seq_len, ent2id, data_type=\"train\",):\n",
        "        batch_data = self.generate_inputs(batch_data, max_seq_len, ent2id, data_type)\n",
        "        sample_list = []\n",
        "        input_ids_list = []\n",
        "        attention_mask_list = []\n",
        "        token_type_ids_list = []\n",
        "        labels_list = []\n",
        "        \n",
        "        for sample in batch_data:\n",
        "            sample_list.append(sample[0])\n",
        "            input_ids_list.append(sample[1])\n",
        "            attention_mask_list.append(sample[2])\n",
        "            token_type_ids_list.append(sample[3])\n",
        "            if data_type != \"test\":\n",
        "                labels_list.append(sample[4])\n",
        "        \n",
        "        batch_input_ids = torch.stack(input_ids_list, dim=0)\n",
        "        batch_attention_mask = torch.stack(attention_mask_list, dim=0)\n",
        "        batch_token_type_ids = torch.stack(token_type_ids_list, dim=0)\n",
        "        batch_labels = torch.stack(labels_list, dim=0) if data_type!=\"test\" else None\n",
        "        \n",
        "        return sample_list, batch_input_ids, batch_attention_mask, batch_token_type_ids, batch_labels\n",
        "    \n",
        "    def decode_ent(self, pred_matrix):\n",
        "        pass\n",
        "\n",
        "class MetricsCalculator(object):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def get_sample_f1(self, y_pred, y_true):\n",
        "        y_pred = torch.gt(y_pred, 0).float()\n",
        "        return 2 * torch.sum(y_true * y_pred) / torch.sum(y_true + y_pred)\n",
        "    \n",
        "    def get_sample_precision(self, y_pred, y_true):\n",
        "        y_pred = torch.gt(y_pred, 0).float()\n",
        "        return torch.sum(y_pred[y_true == 1]) / (y_pred.sum()+1)\n",
        "    \n",
        "    def get_evaluate_fpr(self, y_pred, y_true):\n",
        "        y_pred = y_pred.cpu().numpy()\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        pred = []\n",
        "        true = []\n",
        "        for b, l, start, end in zip(*np.where(y_pred>0)):\n",
        "            pred.append((b, l, start, end))\n",
        "        for b, l, start, end in zip(*np.where(y_true>0)):\n",
        "            true.append((b, l, start, end))\n",
        "\n",
        "        R = set(pred)\n",
        "        T = set(true)\n",
        "        X = len(R & T)+1e-5\n",
        "        Y = len(R)+1e-5\n",
        "        Z = len(T)+1e-5\n",
        "        f1, precision, recall = 2 * X / (Y + Z), X / Y, X / Z\n",
        "        return f1, precision, recall\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "class GlobalPointer(nn.Module):\n",
        "    def __init__(self, encoder, ent_type_size, inner_dim, RoPE=True):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.ent_type_size = ent_type_size\n",
        "        self.inner_dim = inner_dim\n",
        "        self.hidden_size = encoder.config.hidden_size\n",
        "        self.dense = nn.Linear(self.hidden_size, self.ent_type_size * self.inner_dim * 2)\n",
        "\n",
        "        self.RoPE = RoPE\n",
        "    \n",
        "    \n",
        "    def sinusoidal_position_embedding(self, batch_size, seq_len, output_dim):\n",
        "        position_ids = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(-1)\n",
        "\n",
        "        indices = torch.arange(0, output_dim // 2, dtype=torch.float)\n",
        "        indices = torch.pow(10000, -2 * indices / output_dim)\n",
        "        embeddings = position_ids * indices\n",
        "        embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)\n",
        "        embeddings = embeddings.repeat((batch_size, *([1]*len(embeddings.shape))))\n",
        "        embeddings = torch.reshape(embeddings, (batch_size, seq_len, output_dim))\n",
        "        embeddings = embeddings.to(self.device)\n",
        "        return embeddings\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        self.device = input_ids.device\n",
        "        \n",
        "        context_outputs = self.encoder(input_ids, attention_mask, token_type_ids)\n",
        "        # last_hidden_state:(batch_size, seq_len, hidden_size)\n",
        "        last_hidden_state = context_outputs[0]\n",
        "\n",
        "        batch_size = last_hidden_state.size()[0]\n",
        "        seq_len = last_hidden_state.size()[1]\n",
        "\n",
        "        # outputs:(batch_size, seq_len, ent_type_size*inner_dim*2)\n",
        "        outputs = self.dense(last_hidden_state)\n",
        "        outputs = torch.split(outputs, self.inner_dim * 2, dim=-1)\n",
        "        # outputs:(batch_size, seq_len, ent_type_size, inner_dim*2)\n",
        "        outputs = torch.stack(outputs, dim=-2)\n",
        "        # qw,kw:(batch_size, seq_len, ent_type_size, inner_dim)\n",
        "        qw, kw = outputs[...,:self.inner_dim], outputs[...,self.inner_dim:] # TODO:修改为Linear获取？\n",
        "\n",
        "        if self.RoPE:\n",
        "            # pos_emb:(batch_size, seq_len, inner_dim)\n",
        "            pos_emb = self.sinusoidal_position_embedding(batch_size, seq_len, self.inner_dim)\n",
        "            # cos_pos,sin_pos: (batch_size, seq_len, 1, inner_dim)\n",
        "            cos_pos = pos_emb[..., None, 1::2].repeat_interleave(2, dim=-1)\n",
        "            sin_pos = pos_emb[..., None,::2].repeat_interleave(2, dim=-1)\n",
        "            qw2 = torch.stack([-qw[..., 1::2], qw[...,::2]], -1)\n",
        "            qw2 = qw2.reshape(qw.shape)\n",
        "            qw = qw * cos_pos + qw2 * sin_pos\n",
        "            kw2 = torch.stack([-kw[..., 1::2], kw[...,::2]], -1)\n",
        "            kw2 = kw2.reshape(kw.shape)\n",
        "            kw = kw * cos_pos + kw2 * sin_pos\n",
        "            \n",
        "        # logits:(batch_size, ent_type_size, seq_len, seq_len)\n",
        "        logits = torch.einsum('bmhd,bnhd->bhmn', qw, kw)\n",
        "\n",
        "        # padding mask\n",
        "        pad_mask = attention_mask.unsqueeze(1).unsqueeze(1).expand(batch_size, self.ent_type_size, seq_len, seq_len)\n",
        "        # pad_mask_h = attention_mask.unsqueeze(1).unsqueeze(-1).expand(batch_size, self.ent_type_size, seq_len, seq_len)\n",
        "        # pad_mask = pad_mask_v&pad_mask_h\n",
        "        logits = logits*pad_mask - (1-pad_mask)*1e12\n",
        "\n",
        "        # 排除下三角\n",
        "        mask = torch.tril(torch.ones_like(logits), -1) \n",
        "        logits = logits - mask * 1e12\n",
        "        \n",
        "\n",
        "        \n",
        "        return logits/self.inner_dim**0.5\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## config.py"
      ],
      "metadata": {
        "id": "9hKuVrSOMI9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dLKbf9lTjNNj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Date: 2021-06-01 17:18:25\n",
        "LastEditors: GodK\n",
        "\"\"\"\n",
        "import time\n",
        "\n",
        "common = {\n",
        "    \"exp_name\": \"pro2\",\n",
        "    \"encoder\": \"BERT\",\n",
        "    \"data_home\": \"\",\n",
        "    \"bert_path\": \"bert-base-chinese\",  # bert-base-cased， bert-base-chinese\n",
        "    \"run_type\": \"train\",  # train,eval\n",
        "    \"f1_2_save\": 0.5,  # 存模型的最低f1值\n",
        "    \"logger\": \"default\"  # wandb or default，default意味着只输出日志到控制台\n",
        "}\n",
        "\n",
        "# wandb的配置，只有在logger=wandb时生效。用于可视化训练过程\n",
        "wandb_config = {\n",
        "    \"run_name\": time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime()),\n",
        "    \"log_interval\": 10\n",
        "}\n",
        "\n",
        "train_config = {\n",
        "    \"train_data\": \"train.json\",\n",
        "    \"valid_data\": \"dev.json\",\n",
        "    \"ent2id\": \"ent2id.json\",\n",
        "    \"path_to_save_model\": \"./outputs\",  # 在logger不是wandb时生效\n",
        "    \"hyper_parameters\": {\n",
        "        \"lr\": 5e-5,\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": 10,\n",
        "        \"seed\": 2333,\n",
        "        \"max_seq_len\": 128,\n",
        "        \"scheduler\": \"CAWR\"\n",
        "    }\n",
        "}\n",
        "\n",
        "eval_config = {\n",
        "    \"model_state_dir\": \"./outputs/pro2/\",  # 预测时注意填写模型路径（时间tag文件夹）\n",
        "    \"run_id\": \"\",\n",
        "    \"last_k_model\": 1,  # 取倒数第几个model_state\n",
        "    \"test_data\": \"test.json\",\n",
        "    \"ent2id\": \"ent2id.json\",\n",
        "    \"save_res_dir\": \"results\",\n",
        "    \"hyper_parameters\": {\n",
        "        \"batch_size\": 16,\n",
        "        \"max_seq_len\": 512,\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "cawr_scheduler = {\n",
        "    # CosineAnnealingWarmRestarts\n",
        "    \"T_mult\": 1,\n",
        "    \"rewarm_epoch_num\": 2,\n",
        "}\n",
        "step_scheduler = {\n",
        "    # StepLR\n",
        "    \"decay_rate\": 0.999,\n",
        "    \"decay_steps\": 100,\n",
        "}\n",
        "\n",
        "# ---------------------------------------------\n",
        "train_config[\"hyper_parameters\"].update(**cawr_scheduler, **step_scheduler)\n",
        "train_config = {**train_config, **common, **wandb_config}\n",
        "eval_config = {**eval_config, **common}\n"
      ],
      "metadata": {
        "id": "NjjVEQ2yMMle"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluate.py"
      ],
      "metadata": {
        "id": "AU3xvtBeMht9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "ZraAiEtLMYu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb22bca4-8a3c-4f33-a35e-950253d44fd2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.15-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |▌                               | 30 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 61 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 245 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 256 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 266 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 276 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 286 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 296 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 307 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 317 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 327 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 337 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 348 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 358 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 368 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 378 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 389 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 399 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 409 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 419 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 430 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 440 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 450 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 460 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 471 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 481 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 491 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 501 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 512 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 522 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 532 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 542 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 552 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 563 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 573 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 583 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 593 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 604 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 614 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 624 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 634 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 645 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 655 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 665 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 675 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 686 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 696 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 706 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 716 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 727 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 737 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 747 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 757 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 768 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 778 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 788 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 798 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 808 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 819 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 829 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 839 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 849 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 860 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 870 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 880 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 890 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 901 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 911 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 921 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 931 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 942 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 952 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 962 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 972 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 983 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 993 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.0 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.2 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.7 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.7 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.8 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8 MB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 52.8 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=e39da93a1c1d8cd2639c49a053dd5a3bd98e659952aeb8f44bd760f43ef34e30\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.10 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.15\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 58.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 35.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train.py"
      ],
      "metadata": {
        "id": "jqiWM8RgMPSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Date: 2021-05-31 19:50:58\n",
        "LastEditors: GodK\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import json\n",
        "from transformers import BertTokenizerFast, BertModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import wandb\n",
        "import time\n",
        "\n",
        "config = train_config\n",
        "hyper_parameters = config[\"hyper_parameters\"]\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device='cpu'\n",
        "config[\"num_workers\"] = 6 if sys.platform.startswith(\"linux\") else 0\n",
        "\n",
        "# for reproductivity\n",
        "torch.manual_seed(hyper_parameters[\"seed\"])  # pytorch random seed\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if config[\"logger\"] == \"wandb\" and config[\"run_type\"] == \"train\":\n",
        "    # init wandb\n",
        "    wandb.init(project=\"GlobalPointer_\" + config[\"exp_name\"],\n",
        "               config=hyper_parameters  # Initialize config\n",
        "               )\n",
        "    wandb.run.name = config[\"run_name\"] + \"_\" + wandb.run.id\n",
        "\n",
        "    model_state_dict_dir = wandb.run.dir\n",
        "    logger = wandb\n",
        "else:\n",
        "    model_state_dict_dir = os.path.join(config[\"path_to_save_model\"], config[\"exp_name\"],\n",
        "                                        time.strftime(\"%Y-%m-%d_%H.%M.%S\", time.gmtime()))\n",
        "    if not os.path.exists(model_state_dict_dir):\n",
        "        os.makedirs(model_state_dict_dir)\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(config[\"bert_path\"], add_special_tokens=True, do_lower_case=False)\n",
        "\n",
        "\n",
        "def load_data(data_path, data_type=\"train\"):\n",
        "    \"\"\"读取数据集\n",
        "\n",
        "    Args:\n",
        "        data_path (str): 数据存放路径\n",
        "        data_type (str, optional): 数据类型. Defaults to \"train\".\n",
        "\n",
        "    Returns:\n",
        "        (json): train和valid中一条数据格式：{\"text\":\"\",\"entity_list\":[(start, end, label), (start, end, label)...]}\n",
        "    \"\"\"\n",
        "    if data_type == \"train\" or data_type == \"valid\":\n",
        "        # datas = []\n",
        "        # with open(data_path, encoding=\"utf-8\") as f:\n",
        "        #     for line in f:\n",
        "        #         line = json.loads(line)\n",
        "        #         item = {}\n",
        "        #         item[\"text\"] = line[\"text\"]\n",
        "        #         item[\"entity_list\"] = []\n",
        "        #         for k, v in line['label'].items():\n",
        "        #             for spans in v.values():\n",
        "        #                 for start, end in spans:\n",
        "        #                     item[\"entity_list\"].append((start, end, k))\n",
        "        #\n",
        "        #         datas.append(item)\n",
        "        datas = []\n",
        "        with open(data_path, encoding=\"utf-8\") as f:\n",
        "            for line in f.readlines():\n",
        "                line = json.loads(line)\n",
        "                item = {}\n",
        "                item[\"text\"] = line[\"text\"]\n",
        "                item[\"entity_list\"] = []\n",
        "                for k, v in line['label'].items():\n",
        "                    for k_, span in v.items():\n",
        "                        for spans in span:\n",
        "                            item[\"entity_list\"].append((spans[0], spans[1], k))\n",
        "\n",
        "                datas.append(item)\n",
        "        return datas\n",
        "    else:\n",
        "        return json.load(open(data_path, encoding=\"utf-8\"))\n",
        "\n",
        "\n",
        "ent2id_path = os.path.join(config[\"data_home\"], config[\"exp_name\"], config[\"ent2id\"])\n",
        "ent2id = load_data(ent2id_path, \"ent2id\")\n",
        "ent_type_size = len(ent2id)\n",
        "\n",
        "\n",
        "def data_generator(data_type=\"train\"):\n",
        "    \"\"\"\n",
        "    读取数据，生成DataLoader。\n",
        "    \"\"\"\n",
        "\n",
        "    if data_type == \"train\":\n",
        "        train_data_path = os.path.join(config[\"data_home\"], config[\"exp_name\"], config[\"train_data\"])\n",
        "        train_data = load_data(train_data_path, \"train\")\n",
        "        print('train_data_length',len(train_data))\n",
        "        print('examples',train_data[:3])\n",
        "        valid_data_path = os.path.join(config[\"data_home\"], config[\"exp_name\"], config[\"valid_data\"])\n",
        "        valid_data = load_data(valid_data_path, \"valid\")\n",
        "    elif data_type == \"valid\":\n",
        "        valid_data_path = os.path.join(config[\"data_home\"], config[\"exp_name\"], config[\"valid_data\"])\n",
        "        valid_data = load_data(valid_data_path, \"valid\")\n",
        "        train_data = []\n",
        "\n",
        "    all_data = train_data + valid_data\n",
        "\n",
        "    # TODO:句子截取\n",
        "    max_tok_num = 0\n",
        "    for sample in all_data:\n",
        "        tokens = tokenizer(sample[\"text\"])[\"input_ids\"]\n",
        "        max_tok_num = max(max_tok_num, len(tokens))\n",
        "    assert max_tok_num <= hyper_parameters[\"max_seq_len\"], f'数据文本最大token数量{max_tok_num}超过预设{hyper_parameters[\"max_seq_len\"]}'\n",
        "    max_seq_len = min(max_tok_num, hyper_parameters[\"max_seq_len\"])\n",
        "\n",
        "    data_maker = DataMaker(tokenizer)\n",
        "\n",
        "    if data_type == \"train\":\n",
        "        # train_inputs = data_maker.generate_inputs(train_data, max_seq_len, ent2id)\n",
        "        # valid_inputs = data_maker.generate_inputs(valid_data, max_seq_len, ent2id)\n",
        "        train_dataloader = DataLoader(MyDataset(train_data),\n",
        "                                      batch_size=hyper_parameters[\"batch_size\"],\n",
        "                                      shuffle=True,\n",
        "                                      num_workers=config[\"num_workers\"],\n",
        "                                      drop_last=False,\n",
        "                                      collate_fn=lambda x: data_maker.generate_batch(x, max_seq_len, ent2id)\n",
        "                                      )\n",
        "        valid_dataloader = DataLoader(MyDataset(valid_data),\n",
        "                                      batch_size=hyper_parameters[\"batch_size\"],\n",
        "                                      shuffle=True,\n",
        "                                      num_workers=config[\"num_workers\"],\n",
        "                                      drop_last=False,\n",
        "                                      collate_fn=lambda x: data_maker.generate_batch(x, max_seq_len, ent2id)\n",
        "                                      )\n",
        "        # for batch in train_dataloader:\n",
        "        #     print(batch[1].shape)\n",
        "        #     print(hyper_parameters[\"batch_size\"])\n",
        "        #     break\n",
        "        return train_dataloader, valid_dataloader\n",
        "    elif data_type == \"valid\":\n",
        "        # valid_inputs = data_maker.generate_inputs(valid_data, max_seq_len, ent2id)\n",
        "        valid_dataloader = DataLoader(MyDataset(valid_data),\n",
        "                                      batch_size=hyper_parameters[\"batch_size\"],\n",
        "                                      shuffle=True,\n",
        "                                      num_workers=config[\"num_workers\"],\n",
        "                                      drop_last=False,\n",
        "                                      collate_fn=lambda x: data_maker.generate_batch(x, max_seq_len, ent2id)\n",
        "                                      )\n",
        "        return valid_dataloader\n",
        "\n",
        "\n",
        "metrics = MetricsCalculator()\n",
        "\n",
        "\n",
        "def train_step(batch_train, model, optimizer, criterion):\n",
        "    # batch_input_ids:(batch_size, seq_len)    batch_labels:(batch_size, ent_type_size, seq_len, seq_len)\n",
        "    batch_samples, batch_input_ids, batch_attention_mask, batch_token_type_ids, batch_labels = batch_train\n",
        "    batch_input_ids, batch_attention_mask, batch_token_type_ids, batch_labels = (batch_input_ids.to(device),\n",
        "                                                                                 batch_attention_mask.to(device),\n",
        "                                                                                 batch_token_type_ids.to(device),\n",
        "                                                                                 batch_labels.to(device)\n",
        "                                                                                 )\n",
        "\n",
        "    logits = model(batch_input_ids, batch_attention_mask, batch_token_type_ids)\n",
        "\n",
        "    loss = criterion(logits, batch_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    sample_precision = metrics.get_sample_precision(logits, batch_labels)\n",
        "    sample_f1 = metrics.get_sample_f1(logits, batch_labels)\n",
        "\n",
        "    return loss.item(), sample_precision.item(), sample_f1.item()\n",
        "\n",
        "\n",
        "encoder = BertModel.from_pretrained(config[\"bert_path\"])\n",
        "model = GlobalPointer(encoder, ent_type_size, 64)\n",
        "model = model.to(device)\n",
        "\n",
        "if config[\"logger\"] == \"wandb\" and config[\"run_type\"] == \"train\":\n",
        "    wandb.watch(model)\n",
        "\n",
        "\n",
        "def train(model, dataloader, epoch, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    # loss func\n",
        "    def loss_fun(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        y_true:(batch_size, ent_type_size, seq_len, seq_len)\n",
        "        y_pred:(batch_size, ent_type_size, seq_len, seq_len)\n",
        "        \"\"\"\n",
        "        batch_size, ent_type_size = y_pred.shape[:2]\n",
        "        y_true = y_true.reshape(batch_size * ent_type_size, -1)\n",
        "        y_pred = y_pred.reshape(batch_size * ent_type_size, -1)\n",
        "        loss = multilabel_categorical_crossentropy(y_true, y_pred)\n",
        "        return loss\n",
        "\n",
        "    # scheduler\n",
        "    if hyper_parameters[\"scheduler\"] == \"CAWR\":\n",
        "        T_mult = hyper_parameters[\"T_mult\"]\n",
        "        rewarm_epoch_num = hyper_parameters[\"rewarm_epoch_num\"]\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
        "                                                                         len(train_dataloader) * rewarm_epoch_num,\n",
        "                                                                         T_mult)\n",
        "    elif hyper_parameters[\"scheduler\"] == \"Step\":\n",
        "        decay_rate = hyper_parameters[\"decay_rate\"]\n",
        "        decay_steps = hyper_parameters[\"decay_steps\"]\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=decay_steps, gamma=decay_rate)\n",
        "\n",
        "    total_loss, total_precision, total_f1 = 0., 0., 0.\n",
        "    for batch_ind, batch_data in enumerate(dataloader):\n",
        "\n",
        "        loss, precision, f1 = train_step(batch_data, model, optimizer, loss_fun)\n",
        "\n",
        "        total_loss += loss\n",
        "        total_precision += precision\n",
        "        total_f1 += f1\n",
        "\n",
        "        avg_loss = total_loss / (batch_ind + 1)\n",
        "        scheduler.step()\n",
        "\n",
        "        avg_precision = total_precision / (batch_ind + 1)\n",
        "        avg_f1 = total_f1 / (batch_ind + 1)\n",
        "        if batch_ind % 200==0:\n",
        "          print(\n",
        "              f'Project:{config[\"exp_name\"]}, Epoch: {epoch + 1}/{hyper_parameters[\"epochs\"]}, Batch: {batch_ind + 1}/{len(dataloader)}, loss: {avg_loss}, precision: {avg_precision}, f1:{avg_f1}, lr: {optimizer.param_groups[0][\"lr\"]}')\n",
        "        if config[\"logger\"] == \"wandb\" and batch_ind % config[\"log_interval\"] == 0:\n",
        "            logger.log({\n",
        "                \"epoch\": epoch,\n",
        "                \"train_loss\": avg_loss,\n",
        "                \"train_precision\": avg_precision,\n",
        "                \"train_f1\": avg_f1,\n",
        "                \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "            })\n",
        "\n",
        "\n",
        "def valid_step(batch_valid, model):\n",
        "    batch_samples, batch_input_ids, batch_attention_mask, batch_token_type_ids, batch_labels = batch_valid\n",
        "    batch_input_ids, batch_attention_mask, batch_token_type_ids, batch_labels = (batch_input_ids.to(device),\n",
        "                                                                                 batch_attention_mask.to(device),\n",
        "                                                                                 batch_token_type_ids.to(device),\n",
        "                                                                                 batch_labels.to(device)\n",
        "                                                                                 )\n",
        "    with torch.no_grad():\n",
        "        logits = model(batch_input_ids, batch_attention_mask, batch_token_type_ids)\n",
        "    sample_f1, sample_precision, sample_recall = metrics.get_evaluate_fpr(logits, batch_labels)\n",
        "\n",
        "    return sample_f1, sample_precision, sample_recall\n",
        "\n",
        "\n",
        "def valid(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    total_f1, total_precision, total_recall = 0., 0., 0.\n",
        "    for batch_data in tqdm(dataloader, desc=\"Validating\"):\n",
        "        f1, precision, recall = valid_step(batch_data, model)\n",
        "\n",
        "        total_f1 += f1\n",
        "        total_precision += precision\n",
        "        total_recall += recall\n",
        "\n",
        "    avg_f1 = total_f1 / (len(dataloader))\n",
        "    avg_precision = total_precision / (len(dataloader))\n",
        "    avg_recall = total_recall / (len(dataloader))\n",
        "    print(\"******************************************\")\n",
        "    print(f'avg_precision: {avg_precision}, avg_recall: {avg_recall}, avg_f1: {avg_f1}')\n",
        "    print(\"******************************************\")\n",
        "    if config[\"logger\"] == \"wandb\":\n",
        "        logger.log({\"valid_precision\": avg_precision, \"valid_recall\": avg_recall, \"valid_f1\": avg_f1})\n",
        "    return avg_f1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if config[\"run_type\"] == \"train\":\n",
        "        train_dataloader, valid_dataloader = data_generator()\n",
        "        print('len_train_dataloader',len(train_dataloader))\n",
        "        # optimizer\n",
        "        init_learning_rate = float(hyper_parameters[\"lr\"])\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=init_learning_rate)\n",
        "\n",
        "        max_f1 = 0.\n",
        "        for epoch in range(hyper_parameters[\"epochs\"]):\n",
        "            train(model, train_dataloader, epoch, optimizer)\n",
        "            valid_f1 = valid(model, valid_dataloader)\n",
        "            if valid_f1 > max_f1:\n",
        "                max_f1 = valid_f1\n",
        "                if valid_f1 > config[\"f1_2_save\"]:  # save the best model\n",
        "                    modle_state_num = len(glob.glob(model_state_dict_dir + \"/model_state_dict_*.pt\"))\n",
        "                    torch.save(model.state_dict(),\n",
        "                               os.path.join(model_state_dict_dir, \"model_state_dict_{}.pt\".format(modle_state_num)))\n",
        "            print(f\"Best F1: {max_f1}\")\n",
        "            print(\"******************************************\")\n",
        "            if config[\"logger\"] == \"wandb\":\n",
        "                logger.log({\"Best_F1\": max_f1})\n",
        "    elif config[\"run_type\"] == \"eval\":\n",
        "        evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNcJFsAxMRJu",
        "outputId": "ee144346-f984-411c-9a43-01a4cb8eacb6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data_length 10748\n",
            "examples [{'text': '浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，', 'entity_list': [(9, 11, 'name'), (0, 3, 'company')]}, {'text': '生生不息CSOL生化狂潮让你填弹狂扫', 'entity_list': [(4, 7, 'game')]}, {'text': '那不勒斯vs锡耶纳以及桑普vs热那亚之上呢？', 'entity_list': [(0, 3, 'organization'), (6, 8, 'organization'), (11, 12, 'organization'), (15, 17, 'organization')]}]\n",
            "len_train_dataloader 336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project:pro2, Epoch: 1/10, Batch: 1/336, loss: 6.600592136383057, precision: 0.0002596285776235163, f1:0.0005189623916521668, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 1/10, Batch: 201/336, loss: 1.0347090218197648, precision: 0.5221999186135722, f1:0.3898638491414543, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.7194880021807883, avg_recall: 0.8028311059808583, avg_f1: 0.7578333078500072\n",
            "******************************************\n",
            "Best F1: 0.7578333078500072\n",
            "******************************************\n",
            "Project:pro2, Epoch: 2/10, Batch: 1/336, loss: 0.2776467800140381, precision: 0.8309859037399292, f1:0.7712418437004089, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 2/10, Batch: 201/336, loss: 0.22915260701333706, precision: 0.821239360529392, f1:0.788216386861469, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 10.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.7605774153240777, avg_recall: 0.7899067121083995, avg_f1: 0.7743630158828901\n",
            "******************************************\n",
            "Best F1: 0.7743630158828901\n",
            "******************************************\n",
            "Project:pro2, Epoch: 3/10, Batch: 1/336, loss: 0.16657279431819916, precision: 0.8805969953536987, f1:0.8740741014480591, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 3/10, Batch: 201/336, loss: 0.17360484273872565, precision: 0.8545729731445881, f1:0.8430472769547458, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 10.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.7587768930923325, avg_recall: 0.8078984911893782, avg_f1: 0.7816531776492889\n",
            "******************************************\n",
            "Best F1: 0.7816531776492889\n",
            "******************************************\n",
            "Project:pro2, Epoch: 4/10, Batch: 1/336, loss: 0.1914335936307907, precision: 0.8382353186607361, f1:0.8321167826652527, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 4/10, Batch: 201/336, loss: 0.13155619827891463, precision: 0.880441064858318, f1:0.8811883226555971, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 10.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.775344875867493, avg_recall: 0.7951844896011039, avg_f1: 0.7843824523690343\n",
            "******************************************\n",
            "Best F1: 0.7843824523690343\n",
            "******************************************\n",
            "Project:pro2, Epoch: 5/10, Batch: 1/336, loss: 0.06287578493356705, precision: 0.9305555820465088, f1:0.9436619877815247, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 5/10, Batch: 201/336, loss: 0.09993927193740706, precision: 0.9078553837923268, f1:0.9125213379883648, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 11.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.7569564923159408, avg_recall: 0.8149724836660062, avg_f1: 0.7843089997281117\n",
            "******************************************\n",
            "Best F1: 0.7843824523690343\n",
            "******************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project:pro2, Epoch: 6/10, Batch: 1/336, loss: 0.04793429374694824, precision: 0.939393937587738, f1:0.961240291595459, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 6/10, Batch: 201/336, loss: 0.074715699703984, precision: 0.9266110225696469, f1:0.9352318264951753, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 11.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.7670669653981453, avg_recall: 0.7908403853763878, avg_f1: 0.7777223110387479\n",
            "******************************************\n",
            "Best F1: 0.7843824523690343\n",
            "******************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project:pro2, Epoch: 7/10, Batch: 1/336, loss: 0.033512722700834274, precision: 0.9605262875556946, f1:0.9798657894134521, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 7/10, Batch: 201/336, loss: 0.05987925560616735, precision: 0.9392987510458154, f1:0.9496879556878882, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 10.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.7592416479967943, avg_recall: 0.8005817201643859, avg_f1: 0.7783956933384082\n",
            "******************************************\n",
            "Best F1: 0.7843824523690343\n",
            "******************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project:pro2, Epoch: 8/10, Batch: 1/336, loss: 0.04488106444478035, precision: 0.9459459185600281, f1:0.9655172228813171, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 8/10, Batch: 201/336, loss: 0.05019886844064021, precision: 0.9461606752813159, f1:0.9576916507820585, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 10.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.7647344773164042, avg_recall: 0.8088305096905986, avg_f1: 0.7851920355853806\n",
            "******************************************\n",
            "Best F1: 0.7851920355853806\n",
            "******************************************\n",
            "Project:pro2, Epoch: 9/10, Batch: 1/336, loss: 0.05707431584596634, precision: 0.9146341681480408, f1:0.9433962106704712, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 9/10, Batch: 201/336, loss: 0.04423216236430911, precision: 0.9518226607521968, f1:0.9637569924492148, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 10.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.7745565049286722, avg_recall: 0.773190332840184, avg_f1: 0.7729788361870369\n",
            "******************************************\n",
            "Best F1: 0.7851920355853806\n",
            "******************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project:pro2, Epoch: 10/10, Batch: 1/336, loss: 0.018417617306113243, precision: 0.9692307710647583, f1:0.984375, lr: 4.9999726806462766e-05\n",
            "Project:pro2, Epoch: 10/10, Batch: 201/336, loss: 0.03338666553539572, precision: 0.9627969706829508, f1:0.9743371196647188, lr: 3.9751305608428205e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 27/27 [00:02<00:00, 11.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "avg_precision: 0.7760020726286996, avg_recall: 0.7825586430911748, avg_f1: 0.7787655937166015\n",
            "******************************************\n",
            "Best F1: 0.7851920355853806\n",
            "******************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Date: 2021-06-11 13:54:00\n",
        "LastEditors: GodK\n",
        "LastEditTime: 2021-07-19 21:53:18\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import json\n",
        "from transformers import BertTokenizerFast, BertModel\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "config = eval_config\n",
        "hyper_parameters = config[\"hyper_parameters\"]\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "config[\"num_workers\"] = 6 if sys.platform.startswith(\"linux\") else 0\n",
        "\n",
        "# for reproductivity\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(config[\"bert_path\"], add_special_tokens=True, do_lower_case=False)\n",
        "\n",
        "\n",
        "def load_data(data_path, data_type=\"test\"):\n",
        "    if data_type == \"test\":\n",
        "        datas = []\n",
        "        with open(data_path, encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = json.loads(line)\n",
        "                datas.append(line)\n",
        "        return datas\n",
        "    else:\n",
        "        return json.load(open(data_path, encoding=\"utf-8\"))\n",
        "\n",
        "\n",
        "ent2id_path = os.path.join(config[\"data_home\"], config[\"exp_name\"], config[\"ent2id\"])\n",
        "ent2id = load_data(ent2id_path, \"ent2id\")\n",
        "ent_type_size = len(ent2id)\n",
        "\n",
        "\n",
        "def data_generator(data_type=\"test\"):\n",
        "    \"\"\"\n",
        "    读取数据，生成DataLoader。\n",
        "    \"\"\"\n",
        "\n",
        "    if data_type == \"test\":\n",
        "        test_data_path = os.path.join(config[\"data_home\"], config[\"exp_name\"], config[\"test_data\"])\n",
        "        test_data = load_data(test_data_path, \"test\")\n",
        "\n",
        "    all_data = test_data\n",
        "\n",
        "    # TODO:句子截取\n",
        "    max_tok_num = 0\n",
        "    for sample in all_data:\n",
        "        tokens = tokenizer.tokenize(sample[\"text\"])\n",
        "        max_tok_num = max(max_tok_num, len(tokens))\n",
        "    assert max_tok_num <= hyper_parameters[\"max_seq_len\"], f'数据文本最大token数量{max_tok_num}超过预设{hyper_parameters[\"max_seq_len\"]}'\n",
        "    max_seq_len = min(max_tok_num, hyper_parameters[\"max_seq_len\"])\n",
        "\n",
        "    data_maker = DataMaker(tokenizer)\n",
        "\n",
        "    if data_type == \"test\":\n",
        "        # test_inputs = data_maker.generate_inputs(test_data, max_seq_len, ent2id, data_type=\"test\")\n",
        "        test_dataloader = DataLoader(MyDataset(test_data),\n",
        "                                     batch_size=hyper_parameters[\"batch_size\"],\n",
        "                                     shuffle=False,\n",
        "                                     num_workers=config[\"num_workers\"],\n",
        "                                     drop_last=False,\n",
        "                                     collate_fn=lambda x: data_maker.generate_batch(x, max_seq_len, ent2id,\n",
        "                                                                                    data_type=\"test\")\n",
        "                                     )\n",
        "        return test_dataloader\n",
        "\n",
        "\n",
        "def decode_ent(text, pred_matrix, tokenizer, threshold=0):\n",
        "    # print(text)\n",
        "    token2char_span_mapping = tokenizer(text, return_offsets_mapping=True)[\"offset_mapping\"]\n",
        "    id2ent = {id: ent for ent, id in ent2id.items()}\n",
        "    pred_matrix = pred_matrix.cpu().numpy()\n",
        "    ent_list = {}\n",
        "    for ent_type_id, token_start_index, token_end_index in zip(*np.where(pred_matrix > threshold)):\n",
        "        ent_type = id2ent[ent_type_id]\n",
        "        ent_char_span = [token2char_span_mapping[token_start_index][0], token2char_span_mapping[token_end_index][1]]\n",
        "        ent_text = text[ent_char_span[0]:ent_char_span[1]]\n",
        "\n",
        "        ent_type_dict = ent_list.get(ent_type, {})\n",
        "        ent_text_list = ent_type_dict.get(ent_text, [])\n",
        "        ent_text_list.append(ent_char_span)\n",
        "        ent_type_dict.update({ent_text: ent_text_list})\n",
        "        ent_list.update({ent_type: ent_type_dict})\n",
        "    # print(ent_list)\n",
        "    return ent_list\n",
        "\n",
        "\n",
        "def predict(dataloader, model):\n",
        "    predict_res = []\n",
        "\n",
        "    model.eval()\n",
        "    for batch_data in dataloader:\n",
        "        batch_samples, batch_input_ids, batch_attention_mask, batch_token_type_ids, _ = batch_data\n",
        "        batch_input_ids, batch_attention_mask, batch_token_type_ids = (batch_input_ids.to(device),\n",
        "                                                                       batch_attention_mask.to(device),\n",
        "                                                                       batch_token_type_ids.to(device),\n",
        "                                                                       )\n",
        "        with torch.no_grad():\n",
        "            batch_logits = model(batch_input_ids, batch_attention_mask, batch_token_type_ids)\n",
        "\n",
        "        for ind in range(len(batch_samples)):\n",
        "            gold_sample = batch_samples[ind]\n",
        "            text = gold_sample[\"text\"]\n",
        "            text_id = gold_sample[\"id\"]\n",
        "            pred_matrix = batch_logits[ind]\n",
        "            labels = decode_ent(text, pred_matrix, tokenizer)\n",
        "            predict_res.append({\"id\": text_id, \"text\": text, \"label\": labels})\n",
        "    return predict_res\n",
        "\n",
        "\n",
        "def load_model():\n",
        "    # model_state_dir = config[\"model_state_dir\"]\n",
        "    model_state_dir = 'outputs/pro2/2022-04-23_07.09.44'\n",
        "    model_state_list = sorted(filter(lambda x: \"model_state\" in x, os.listdir(model_state_dir)),\n",
        "                              key=lambda x: int(x.split(\".\")[0].split(\"_\")[-1]))\n",
        "    last_k_model = config[\"last_k_model\"]\n",
        "    model_state_path = os.path.join(model_state_dir, model_state_list[-last_k_model])\n",
        "\n",
        "    encoder = BertModel.from_pretrained(config[\"bert_path\"])\n",
        "    model = GlobalPointer(encoder, ent_type_size, 64)\n",
        "    model.load_state_dict(torch.load(model_state_path))\n",
        "    model = model.to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate():\n",
        "    test_dataloader = data_generator(data_type=\"test\")\n",
        "\n",
        "    model = load_model()\n",
        "\n",
        "    predict_res = predict(test_dataloader, model)\n",
        "\n",
        "    if not os.path.exists(os.path.join(config[\"save_res_dir\"], config[\"exp_name\"])):\n",
        "        os.mkdir(os.path.join(config[\"save_res_dir\"], config[\"exp_name\"]))\n",
        "    save_path = os.path.join(config[\"save_res_dir\"], config[\"exp_name\"], \"predict_result.json\")\n",
        "    # json.dump(predict_res, open(save_path, \"w\", encoding=\"utf-8\"), ensure_ascii=False)\n",
        "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for item in predict_res:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAd0Fpm3Mjxa",
        "outputId": "9ccf109a-0986-4ecf-a36e-61c9247c464c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4lk45-BibNFF"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}
